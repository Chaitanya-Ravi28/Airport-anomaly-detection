{"cells":[{"cell_type":"code","execution_count":null,"id":"28b66710-9a84-4ec9-8ae7-be23628a4fd8","metadata":{"id":"28b66710-9a84-4ec9-8ae7-be23628a4fd8","outputId":"ff18cf92-5ca8-4cf7-b788-2a162f6fb310"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found existing installation: tensorflow 2.15.0\n","Uninstalling tensorflow-2.15.0:\n","  Successfully uninstalled tensorflow-2.15.0\n","\u001b[33mWARNING: Skipping tensorflow-intel as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping tensorflow-cpu as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mFound existing installation: keras 2.15.0\n","Uninstalling keras-2.15.0:\n","  Successfully uninstalled keras-2.15.0\n","Found existing installation: ml-dtypes 0.2.0\n","Uninstalling ml-dtypes-0.2.0:\n","  Successfully uninstalled ml-dtypes-0.2.0\n"]}],"source":["!pip uninstall -y tensorflow tensorflow-intel tensorflow-cpu keras ml-dtypes\n"]},{"cell_type":"code","execution_count":null,"id":"56c815d0-161c-43eb-af9f-bebac4e015c0","metadata":{"id":"56c815d0-161c-43eb-af9f-bebac4e015c0","outputId":"9d034c3b-7663-4d31-fb0b-e06ad706b628"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Package(s) not found: tensorflow\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip show tensorflow\n"]},{"cell_type":"code","execution_count":null,"id":"ab7e8450-8749-4c4e-9e69-d7f05e96e31d","metadata":{"id":"ab7e8450-8749-4c4e-9e69-d7f05e96e31d"},"outputs":[],"source":["!pip install --quiet torch torchvision torchaudio opencv-python pandas scikit-learn\n"]},{"cell_type":"code","execution_count":null,"id":"7d3429cb-8f81-44c5-89bc-27467f656546","metadata":{"id":"7d3429cb-8f81-44c5-89bc-27467f656546","outputId":"a10dbcfe-aef5-4f5d-a5c4-87818bdd07e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Torch: 2.5.1+cu124\n","NumPy: 2.2.6\n"]}],"source":["import torch, numpy as np\n","print(\"Torch:\", torch.__version__)\n","print(\"NumPy:\", np.__version__)\n"]},{"cell_type":"code","execution_count":null,"id":"6155c778-ca71-4693-831a-1ee763ff23a2","metadata":{"id":"6155c778-ca71-4693-831a-1ee763ff23a2","outputId":"b84b9e59-b3bf-41df-8eab-2bb1dd86e810"},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úÖ Using device: cuda\n"]}],"source":["import os, json, random, math, cv2\n","from pathlib import Path\n","import numpy as np\n","import pandas as pd\n","from datetime import datetime\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.preprocessing import MinMaxScaler\n","\n","BASE = Path.home() / \"Video_analysis+IOT\"\n","TRAIN_VID_DIR = BASE / \"training_videos\"\n","TEST_VID_DIR = BASE / \"testing_videos\"\n","IOT_DIR = BASE / \"iot_data\"\n","OUTPUT_DIR = BASE / \"outputs\"\n","\n","for p in (TRAIN_VID_DIR, TEST_VID_DIR, IOT_DIR, OUTPUT_DIR):\n","    p.mkdir(parents=True, exist_ok=True)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"‚úÖ Using device:\", device)\n"]},{"cell_type":"code","execution_count":null,"id":"e55259df-c4e4-4a92-9936-30630b8fcaf8","metadata":{"id":"e55259df-c4e4-4a92-9936-30630b8fcaf8","outputId":"303d1343-009a-4749-e042-94ba8c2309a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["üéûÔ∏è Loaded 15168 sequences from /home/jovyan/Video_analysis+IOT/training_videos\n","üéûÔ∏è Loaded 15114 sequences from /home/jovyan/Video_analysis+IOT/testing_videos\n"]}],"source":["def load_videos_as_sequences(folder, seq_len=10, resize=(64,64)):\n","    all_seqs = []\n","    for vid_file in sorted(folder.glob(\"*.avi\")):\n","        cap = cv2.VideoCapture(str(vid_file))\n","        frames = []\n","        while True:\n","            ret, frame = cap.read()\n","            if not ret:\n","                break\n","            frame = cv2.resize(frame, resize)\n","            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","            gray = gray.astype(np.float32) / 255.0\n","            frames.append(gray)\n","        cap.release()\n","        frames = np.array(frames)\n","        if len(frames) < seq_len:\n","            continue\n","        for i in range(0, len(frames) - seq_len):\n","            seq = frames[i:i+seq_len]\n","            all_seqs.append(seq)\n","    if len(all_seqs) == 0:\n","        print(\"‚ö†Ô∏è No videos found or too short. Please ensure .avi files exist in:\", folder)\n","        return np.zeros((0, 1, seq_len, resize[0], resize[1]), dtype=np.float32)\n","    all_seqs = np.array(all_seqs)\n","    all_seqs = all_seqs[:, np.newaxis, :, :, :]  # (N,1,T,H,W)\n","    print(f\"üéûÔ∏è Loaded {len(all_seqs)} sequences from {folder}\")\n","    return all_seqs\n","\n","train_data = load_videos_as_sequences(TRAIN_VID_DIR)\n","test_data = load_videos_as_sequences(TEST_VID_DIR)\n"]},{"cell_type":"code","execution_count":null,"id":"95fee614-086d-4624-bbdf-a229db719515","metadata":{"id":"95fee614-086d-4624-bbdf-a229db719515"},"outputs":[],"source":["class VideoDataset(Dataset):\n","    def __init__(self, arr): self.x = torch.from_numpy(arr).float()\n","    def __len__(self): return len(self.x)\n","    def __getitem__(self, idx): return self.x[idx]\n","\n","class Conv3DAE(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.enc = nn.Sequential(\n","            nn.Conv3d(1, 16, 3, padding=1), nn.ReLU(),\n","            nn.MaxPool3d((1,2,2)),\n","            nn.Conv3d(16, 32, 3, padding=1), nn.ReLU(),\n","            nn.MaxPool3d((1,2,2))\n","        )\n","        self.dec = nn.Sequential(\n","            nn.ConvTranspose3d(32,16,kernel_size=(1,2,2),stride=(1,2,2)), nn.ReLU(),\n","            nn.ConvTranspose3d(16,1,kernel_size=(1,2,2),stride=(1,2,2)), nn.Sigmoid()\n","        )\n","    def forward(self, x):\n","        return self.dec(self.enc(x))\n"]},{"cell_type":"code","execution_count":null,"id":"fb1c2916-0936-4139-9475-6416a4b9c755","metadata":{"id":"fb1c2916-0936-4139-9475-6416a4b9c755","outputId":"c93754a7-ab58-4e3f-d59d-42bf6d2224f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["üöÄ Training video model...\n","Epoch 1 | Loss: 0.005602\n","Epoch 2 | Loss: 0.002572\n","Epoch 3 | Loss: 0.002180\n","Epoch 4 | Loss: 0.001974\n","Epoch 5 | Loss: 0.001845\n","Epoch 6 | Loss: 0.001760\n","Epoch 7 | Loss: 0.001698\n","Epoch 8 | Loss: 0.001649\n","Epoch 9 | Loss: 0.001610\n","Epoch 10 | Loss: 0.001575\n","Epoch 11 | Loss: 0.001544\n","Epoch 12 | Loss: 0.001520\n","Epoch 13 | Loss: 0.001495\n","Epoch 14 | Loss: 0.001474\n","Epoch 15 | Loss: 0.001455\n","Epoch 16 | Loss: 0.001437\n","Epoch 17 | Loss: 0.001423\n","Epoch 18 | Loss: 0.001410\n","Epoch 19 | Loss: 0.001397\n","Epoch 20 | Loss: 0.001387\n","üíæ Saved video model to: /home/jovyan/Video_analysis+IOT/outputs/video_conv3d_ae.pth\n"]}],"source":["#Cell 4 ‚Äî Train Video Autoencoder\n","if len(train_data) == 0:\n","    print(\"‚ö†Ô∏è No training data, please add videos to training_videos/.\")\n","else:\n","    train_loader = DataLoader(VideoDataset(train_data), batch_size=8, shuffle=True)\n","    model = Conv3DAE().to(device)\n","    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n","    loss_fn = nn.MSELoss()\n","\n","    print(\"üöÄ Training video model...\")\n","    for epoch in range(20):\n","        total = 0\n","        for x in train_loader:\n","            x = x.to(device)\n","            out = model(x)\n","            loss = loss_fn(out, x)\n","            opt.zero_grad(); loss.backward(); opt.step()\n","            total += loss.item() * x.size(0)\n","        print(f\"Epoch {epoch+1} | Loss: {total/len(train_loader.dataset):.6f}\")\n","\n","    torch.save(model.state_dict(), str(OUTPUT_DIR/\"video_conv3d_ae.pth\"))\n","    print(\"üíæ Saved video model to:\", OUTPUT_DIR/\"video_conv3d_ae.pth\")\n"]},{"cell_type":"code","execution_count":null,"id":"d57a517d-2a84-4f12-ace3-0c49090eae7a","metadata":{"id":"d57a517d-2a84-4f12-ace3-0c49090eae7a","outputId":"b0ed1b43-e797-4624-8a69-d3a6304c5234"},"outputs":[{"name":"stdout","output_type":"stream","text":[" 306 anomalies detected. Saved -> video_anomalies.json\n"]}],"source":["#Cell 5 ‚Äî Detect Video Anomalies\n","if len(test_data) == 0:\n","    print(\"‚ö†Ô∏è No test data found. Please add videos to testing_videos/.\")\n","else:\n","    test_loader = DataLoader(VideoDataset(test_data), batch_size=8, shuffle=False)\n","    model.eval()\n","    errors = []\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            batch = batch.to(device)\n","            out = model(batch)\n","            mse = torch.mean((out - batch)**2, dim=[1,2,3,4]).cpu().numpy()\n","            errors.extend(mse.tolist())\n","\n","    errors = np.array(errors)\n","    thresh = float(errors.mean() + 3*errors.std())\n","    anomalies = [{\"timestamp\": str(datetime.now()), \"index\": int(i),\n","                  \"recon_error\": float(e), \"anomaly_type\": \"Crowd Movement\"}\n","                 for i, e in enumerate(errors) if e > thresh]\n","\n","    with open(OUTPUT_DIR/\"video_anomalies.json\", \"w\") as f:\n","        json.dump(anomalies, f, indent=4)\n","\n","    print(f\" {len(anomalies)} anomalies detected. Saved -> video_anomalies.json\")\n"]},{"cell_type":"code","execution_count":null,"id":"95665efb-1ecf-4015-890b-97c6afb0a63c","metadata":{"id":"95665efb-1ecf-4015-890b-97c6afb0a63c","outputId":"0fa5ddfa-9c8c-4167-8a8e-e57d66cb3148"},"outputs":[{"name":"stdout","output_type":"stream","text":["IoT simulated: /home/jovyan/Video_analysis+IOT/iot_data/iot_train.csv\n"]}],"source":["#Cell 6 ‚Äî Simulate IoT Data\n","def simulate_iot_data(days=2, freq='1min', anomaly_prob=0.02):\n","    timestamps = pd.date_range(datetime.now(), periods=int(24*60*days), freq=freq)\n","    df = pd.DataFrame({\n","        \"timestamp\": timestamps,\n","        \"temperature\": 25 + np.random.normal(0, 0.4, len(timestamps)),\n","        \"humidity\": 50 + np.random.normal(0, 1, len(timestamps)),\n","        \"vibration\": 0.03 + np.random.normal(0, 0.01, len(timestamps))\n","    })\n","    for i in range(len(df)):\n","        if random.random() < anomaly_prob:\n","            col = random.choice([\"temperature\", \"humidity\", \"vibration\"])\n","            df.at[i, col] += random.choice([5, -5, 7, -7])\n","    df.to_csv(IOT_DIR/\"iot_train.csv\", index=False)\n","    print(\"IoT simulated:\", IOT_DIR/\"iot_train.csv\")\n","    return df\n","\n","iot_df = simulate_iot_data()\n"]},{"cell_type":"code","execution_count":null,"id":"1fc503ab-f2fa-4d00-b6a1-9ddf463303d6","metadata":{"id":"1fc503ab-f2fa-4d00-b6a1-9ddf463303d6","outputId":"7e81744f-40f4-4af2-fa07-7d61cdf5c043"},"outputs":[{"name":"stdout","output_type":"stream","text":["IoT Epoch 1 Loss: 0.039735\n","IoT Epoch 2 Loss: 0.006249\n","IoT Epoch 3 Loss: 0.004376\n","IoT Epoch 4 Loss: 0.003308\n","IoT Epoch 5 Loss: 0.003197\n","IoT Epoch 6 Loss: 0.003186\n","IoT Epoch 7 Loss: 0.003187\n","IoT Epoch 8 Loss: 0.003185\n","IoT Epoch 9 Loss: 0.003186\n","IoT Epoch 10 Loss: 0.003183\n","Saved IoT model: /home/jovyan/Video_analysis+IOT/outputs/iot_lstm_ae.pth\n"]}],"source":["#Cell 7 ‚Äî Train IoT LSTM Autoencoder\n","from torch.utils.data import TensorDataset\n","scaler = MinMaxScaler()\n","scaled = scaler.fit_transform(iot_df[[\"temperature\",\"humidity\",\"vibration\"]])\n","\n","SEQ = 30\n","X = np.array([scaled[i:i+SEQ] for i in range(len(scaled)-SEQ)])\n","X = torch.tensor(X).float()\n","\n","train_loader_iot = DataLoader(TensorDataset(X), batch_size=64, shuffle=True)\n","\n","class LSTM_AE(nn.Module):\n","    def __init__(self, n_feat=3, hidden=64):\n","        super().__init__()\n","        self.encoder = nn.LSTM(n_feat, hidden, batch_first=True)\n","        self.decoder = nn.LSTM(hidden, hidden, batch_first=True)\n","        self.fc = nn.Linear(hidden, n_feat)\n","    def forward(self, x):\n","        _, (h, _) = self.encoder(x)\n","        rep = h.repeat(x.size(1), 1, 1).transpose(0,1)\n","        out, _ = self.decoder(rep)\n","        return self.fc(out)\n","\n","iot_model = LSTM_AE().to(device)\n","opt = torch.optim.Adam(iot_model.parameters(), lr=1e-3)\n","loss_fn = nn.MSELoss()\n","for ep in range(10):\n","    tot = 0\n","    for b in train_loader_iot:\n","        b = b[0].to(device)\n","        out = iot_model(b)\n","        loss = loss_fn(out, b)\n","        opt.zero_grad()\n","        loss.backward()\n","        opt.step()\n","        tot += loss.item() * b.size(0)\n","    print(f\"IoT Epoch {ep+1} Loss: {tot/len(train_loader_iot.dataset):.6f}\")\n","\n","\n","torch.save(iot_model.state_dict(), str(OUTPUT_DIR/\"iot_lstm_ae.pth\"))\n","print(\"Saved IoT model:\", OUTPUT_DIR/\"iot_lstm_ae.pth\")\n"]},{"cell_type":"code","execution_count":null,"id":"e2d7837e-789f-45e0-a8af-6ebc85475d1d","metadata":{"id":"e2d7837e-789f-45e0-a8af-6ebc85475d1d","outputId":"962a295d-1f81-4f5b-ba3e-3fe8ed545218"},"outputs":[{"name":"stdout","output_type":"stream","text":[" 32 IoT anomalies detected. Saved -> iot_anomalies.json\n"]}],"source":["#Cell 8 ‚Äî IoT Anomaly Detection\n","recon = []\n","iot_model.eval()\n","recon = []\n","with torch.no_grad():\n","    for b in train_loader_iot:\n","        b = b[0].to(device)\n","        out = iot_model(b)\n","        mse = torch.mean((out - b)**2, dim=(1,2)).cpu().numpy()\n","        recon.extend(mse)\n","\n","recon = np.array(recon)\n","thr = float(recon.mean() + 3*recon.std())\n","\n","iot_anomalies = [{\"timestamp\": str(iot_df.iloc[i+SEQ][\"timestamp\"]),\n","                  \"recon_error\": float(recon[i]),\n","                  \"anomaly_type\": \"IoT Sensor\"}\n","                 for i in range(len(recon)) if recon[i] > thr]\n","\n","with open(OUTPUT_DIR/\"iot_anomalies.json\", \"w\") as f:\n","    json.dump(iot_anomalies, f, indent=4)\n","\n","print(f\" {len(iot_anomalies)} IoT anomalies detected. Saved -> iot_anomalies.json\")\n"]},{"cell_type":"code","execution_count":null,"id":"5631f88e-8102-4f44-9a65-29393c5f3471","metadata":{"id":"5631f88e-8102-4f44-9a65-29393c5f3471"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}